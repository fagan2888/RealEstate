{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1>Neural Network Model</h1> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are reading data that we already prepared. We will look at the first few columns and we will choose 78. district to work on a small subset first.  \n",
    "Finally we will use one hot encoding for categorical features then split the data for train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'C:/Users/kazIm/Desktop/projects/IE490/input/tubitak_data2_processesed.csv'\n",
    "df = pd.read_csv(fileName,  sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preview data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ilce 79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.index[df.ilce_kod!=79],inplace=True)\n",
    "# df\n",
    "df.drop('ilce_kod',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mahalle = df[\"mahalle_kod\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mahalle_kod'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can drop yasal burut alani as it has almost 1 correlation with mevcut alan\n",
    "df = df.drop('yasal_burut_alani',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mahalle = df['mahalle_kod']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding for Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.get_dummies(df, columns=[\"\"])\n",
    "df = pd.get_dummies(df, columns=[\"mahalle_kod\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "X = df.drop('adil_piyasa_degeri_yasal_durum',axis=1)\n",
    "Y = df['adil_piyasa_degeri_yasal_durum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Develop a Baseline Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Keras wrappers require a function as an argument. This function that we must define is responsible for creating the neural network model to be evaluated.\n",
    "    \n",
    "Below we define the function to create the baseline model to be evaluated. It is a simple model that has a single fully connected hidden layer with the same number of neurons as input attributes (9). The network uses rectifier activation function (relu) for the hidden layer. No activation function is used for the output layer because it is a regression problem and we want to predict numerical values directly without transform.\n",
    "    \n",
    "The efficient ADAM optimization algorithm is used and a mean squared error loss function is optimized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "dims = X.shape[1]\n",
    "# define base model\n",
    "  \n",
    "def baseline_model():\n",
    "\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(dims, input_shape=(dims,), init = 'normal', activation='relu'))\n",
    "    model.add(Dense(9, init = 'normal', activation='relu'))\n",
    "    model.add(Dense(1, init = 'normal'))\n",
    "    # compile model\n",
    "#     sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mse', optimizer = 'adam', metrics=['mape'])\n",
    "#     model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot history of model learning \n",
    "def plot_history(network_history):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(network_history.history['loss'])\n",
    "    plt.plot(network_history.history['val_loss'])\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MAPE')\n",
    "    plt.plot(network_history.history['mean_absolute_percentage_error'])\n",
    "    plt.plot(network_history.history['val_mean_absolute_percentage_error'])\n",
    "    plt.legend(['Training', 'Validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also initialize the random number generator with a constant random seed, a process we will repeat for each model evaluated in this tutorial. This is an attempt to ensure we compare models consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "# evaluate model \n",
    "early_stop = EarlyStopping(monitor='val_mean_absolute_percentage_error', patience=50, verbose=0)\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=1000, batch_size=128, verbose=0,\n",
    "                          callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and Validation Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split( X, Y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = estimator.fit(Xtrain, Ytrain, validation_data=(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Cross Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to evaluate this baseline model. We will use 3-fold cross validation to evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is not implemented before hand, we will write our Mean Absolute Percentage Error function and 20% error quartile function to use in `cross_val_score function` of scikit-learn library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    try:\n",
    "        return np.mean(np.abs((y_true - y_pred) / np.abs(y_true)) * 100)\n",
    "    except:\n",
    "        return np.mean((np.abs(y_true - y_pred)+0.001 ) / (np.abs(y_true)+0.001) * 100)\n",
    "\n",
    "def absolute_twenty_percent_error_quartile(y_true, y_pred): \n",
    "    \n",
    "    pred = y_pred.reshape(-1,1) \n",
    "    actual = y_true.reshape(-1,1)\n",
    "    error = np.abs(pred-actual)/np.abs(actual)\n",
    "    return (error[error<=0.2].shape[0]/actual.shape[0])*100\n",
    "    \n",
    "mape = make_scorer(mean_absolute_percentage_error, greater_is_better=False)\n",
    "twentyPercentErrorQuantile = make_scorer(absolute_twenty_percent_error_quartile, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=3, random_state=seed)\n",
    "estimator2 = KerasRegressor(build_fn=baseline_model, epochs=800, batch_size=128, verbose=0)\n",
    "results = np.abs(cross_val_score(estimator2, X, Y, cv=kfold, scoring = mape))\n",
    "print(results)\n",
    "print()\n",
    "print(\"Cross Validation Mean Absolute Percentage error: %.2f \" % (results.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  kfold = StratifiedKFold(n_splits=3, random_state=seed)\n",
    "# results = np.abs(cross_val_score(estimator, X, Y, cv=kfold, scoring = twentyPercentErrorQuantile))\n",
    "# print(results)\n",
    "# print()\n",
    "# print(\"Cross Validation 20 percent error quartile: %.2f \" % (results.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All sample MAPE error and 20% error quartile score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_absolute_percentage_error(estimator.predict(X),Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_twenty_percent_error_quartile(estimator.predict(X),Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Out of Sample sample MAPE error and 20% error quartile score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_absolute_percentage_error(estimator.predict(Xtest),Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_twenty_percent_error_quartile(estimator.predict(Xtest),Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling The Standardized Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important concern with our house price dataset is that the input attributes all vary in their scales because they measure different quantities. \n",
    "\n",
    "It is almost always good practice to prepare our data before modeling it using a neural network model for optimization algorithms' efficiency.  \n",
    "\n",
    "Continuing on from the above baseline model, we can re-evaluate the same model using a scaled version (0-1) of the input dataset. \n",
    "\n",
    "** It is important that we should not use the test data for scaling process other wise it leads to information leakage from testset**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# evaluate model with standardized dataset\n",
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=400, batch_size=32, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "\n",
    "# using 3-fold cross validation again\n",
    "kfold = StratifiedKFold(n_splits=3, random_state=seed)\n",
    "results = np.abs(cross_val_score(pipeline, X, Y, cv=kfold, scoring = mape))\n",
    "print(results)\n",
    "print()\n",
    "print(\"Cross Validation Mean Absolute Percentage error: %.2f \" % (results.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All sample MAPE error and 20% error quartile score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_percentage_error(pipeline.predict(X),Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_twenty_percent_error_quartile(pipeline.predict(X),Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Out of Sample sample MAPE error and 20% error quartile score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(estimators)\n",
    "pipeline.fit(Xtrain,Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_absolute_percentage_error(pipeline.predict(Xtest),Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_twenty_percent_error_quartile(pipeline.predict(Xtest),Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A further extension would be to similarly apply a rescaling to the output variable such as normalizing it to the range of 0-1 and use a Sigmoid or similar activation function on the output layer to narrow output predictions to the same range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tune The Neural Network Topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many concerns that can be optimized for a neural network model.\n",
    "Perhaps the most important one is the structure of the network itself, including the number of layers and the number of neurons in each layer.  \n",
    "\n",
    "In this section, we will evaluate two additional network topologies in an effort to further improve the performance of the model. We will look at both a deeper and a wider network topology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Evaluate a Deeper Network Topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to improve the performance a neural network is to add more layers. This might allow the model to extract and recombine higher order features embedded in the data.  \n",
    "\n",
    "In this section we will evaluate the effect of adding one more hidden layer to the model. This new layer will have about half the number of neurons. Because there are heuristics that suggest that number of neurons in the next layer should not exceed the half of the previuos layer's number of neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(dims, input_shape=(dims,), init = 'normal', activation='relu'))\n",
    "    model.add(Dense(9, init = 'normal', activation='relu'))\n",
    "    model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, init = 'normal'))\n",
    "    # compile model\n",
    "#     sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mse', optimizer = 'adam', metrics=['mape'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will follow the same methodology as above;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model with standardized dataset\n",
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=larger_model, epochs=400, batch_size=32, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "\n",
    "# using 3-fold cross validation again\n",
    "kfold = StratifiedKFold(n_splits=3, random_state=seed)\n",
    "results = np.abs(cross_val_score(pipeline, X, Y, cv=kfold, scoring = mape))\n",
    "print(results)\n",
    "print()\n",
    "print(\"Cross Validation Mean Absolute Percentage error: %.2f \" % (results.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Evaluate a Wider Network Topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach to increasing the representational capability of the model is to create a wider network.  \n",
    "In this section we evaluate the effect of keeping a shallow network architecture and nearly doubling the number of neurons in the one hidden layer.  \n",
    "Here, we have increased the number of neurons in the hidden layer compared to the baseline model from 9 to 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define wider model\n",
    "def wider_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(dims, input_shape=(dims,), kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # compile model\n",
    "#     sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mse', optimizer = 'adam', metrics=['mape'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again evaluating the model structure in same way;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model with standardized dataset\n",
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=wider_model, epochs=400, batch_size=32, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "\n",
    "# using 3-fold cross validation again\n",
    "kfold = StratifiedKFold(n_splits=3, random_state=seed)\n",
    "results = np.abs(cross_val_score(pipeline, X, Y, cv=kfold, scoring = mape))\n",
    "print(results)\n",
    "print()\n",
    "print(\"Cross Validation Mean Absolute Percentage error: %.2f \" % (results.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** We saw that deeper model is the best of the three.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to add another layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "def larger_model2():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(dims, input_shape=(dims,), init = 'normal', activation='relu'))\n",
    "    model.add(Dense(9, init = 'normal', activation='relu'))\n",
    "    model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(2, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, init = 'normal'))\n",
    "    # compile model\n",
    "#     sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mse', optimizer = 'adam', metrics=['mape'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will follow the same methodology as above;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model with standardized dataset\n",
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=larger_model2, epochs=400, batch_size=32, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "\n",
    "# using 3-fold cross validation again\n",
    "kfold = StratifiedKFold(n_splits=3, random_state=seed)\n",
    "results = np.abs(cross_val_score(pipeline, X, Y, cv=kfold, scoring = mape))\n",
    "print(results)\n",
    "print()\n",
    "print(\"Cross Validation Mean Absolute Percentage error: %.2f \" % (results.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That did not improve our model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
